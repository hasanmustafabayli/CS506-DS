{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Worksheet 05\n",
    "\n",
    "Name:  Hasan Mustafbayli\n",
    "UID:  U15717116\n",
    "\n",
    "### Topics\n",
    "\n",
    "- Cost Functions\n",
    "- Kmeans\n",
    "\n",
    "### Cost Function\n",
    "\n",
    "Solving Data Science problems often starts by defining a metric with which to evaluate solutions were you able to find some. This metric is called a cost function. Data Science then backtracks and tries to find a process / algorithm to find solutions that can optimize for that cost function.\n",
    "\n",
    "For example suppose you are asked to cluster three points A, B, C into two non-empty clusters. If someone gave you the solution `{A, B}, {C}`, how would you evaluate that this is a good solution?\n",
    "\n",
    "Notice that because the clusters need to be non-empty and all points must be assigned to a cluster, it must be that two of the three points will be together in one cluster and the third will be alone in the other cluster.\n",
    "\n",
    "In the above solution, if A and B are closer than A and C, and B and C, then this is a good solution. The smaller the distance between the two points in the same cluster (here A and B), the better the solution. So we can define our cost function to be that distance (between A and B here)!\n",
    "\n",
    "The algorithm / process would involve clustering together the two closest points and put the third in its own cluster. This process optimizes for that cost function because no other pair of points could have a lower distance (although it could equal it)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K means\n",
    "\n",
    "a) (1-dimensional clustering) Walk through Lloyd's algorithm step by step on the following dataset:\n",
    "\n",
    "`[0, .5, 1.5, 2, 6, 6.5, 7]` (note: each of these are 1-dimensional data points)\n",
    "\n",
    "Given the initial centroids:\n",
    "\n",
    "`[0, 2]`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 1:\n",
    "\n",
    "Cluster 1: [0, 0.5]\n",
    "Cluster 2: [1.5, 2, 6, 6.5, 7]\n",
    "Step 2:\n",
    "\n",
    "New centroids: [0.25, 4.6]\n",
    "Step 3:\n",
    "\n",
    "Cluster 1: [0, 0.5, 1.5, 2]\n",
    "Cluster 2: [6, 6.5, 7]\n",
    "Step 4:\n",
    "\n",
    "New centroids: [1, 6.5]\n",
    "Step 5:\n",
    "\n",
    "Cluster 1: [0, 0.5, 1.5, 2]\n",
    "Cluster 2: [6, 6.5, 7]\n",
    "Step 6:\n",
    "\n",
    "Further computation shows that the clusters remain the same, indicating convergence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) Describe in plain english what the cost function for k means is."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The k-means cost function quantifies how well data points are grouped into clusters by measuring the total distance between each data point and its assigned cluster's centroid. A lower total distance indicates better clustering, where data points are closer to their cluster centers. The goal of the k-means algorithm is to minimize this cost function by iteratively adjusting cluster assignments and centroids to find an optimal clustering solution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c) For the same number of clusters K, why could there be very different solutions to the K means algorithm on a given dataset?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, the initial centroids selected can have a substantial impact on the initial grouping of data points, potentially leading to different cluster assignments. Additionally, the k-means algorithm may converge to a local minimum of the cost function, which may not necessarily be the global minimum, resulting in different final clustering solutions. Lastly, the order in which data points are processed can also influence the final clustering outcome. These factors highlight the sensitivity of k-means to its initial conditions and optimization process, which can result in distinct clustering results even when applying the algorithm to the same dataset with the same K value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d) Does Lloyd's Algorithm always converge? Why / why not?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lloyd's Algorithm in k-means clustering generally converges.\n",
    "It may converge to a local optimum rather than the global optimum.\n",
    "The cost function's non-convex nature and centroid initialization sensitivity contribute to this behavior.\n",
    "At each step (assignment and update), the algorithm maintains or decreases the cost, ensuring convergence to some minimum.\n",
    "However, the global minimum is not guaranteed, leading to potential sub-optimal solutions in k-means clustering."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "e) Follow along in class the implementation of Kmeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image as im\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn.datasets as datasets\n",
    "\n",
    "centers = [[0, 0], [2, 2], [-3, 2], [2, -4]]\n",
    "X, _ = datasets.make_blobs(n_samples=300, centers=centers, cluster_std=1, random_state=0)\n",
    "# print(X)\n",
    "\n",
    "class KMeans():\n",
    "\n",
    "    def __init__(self, data, k):\n",
    "        self.data = data\n",
    "        self.k = k\n",
    "        self.assignment = [-1 for _ in range(len(data))]\n",
    "        self.snaps = []\n",
    "    \n",
    "    def snap(self, centers):\n",
    "        # print(5)\n",
    "        TEMPFILE = \"temp.png\"\n",
    "\n",
    "        fig, ax = plt.subplots()\n",
    "        ax.scatter(X[:, 0], X[:, 1], c=self.assignment)\n",
    "        ax.scatter(centers[:,0], centers[:, 1], c='r')\n",
    "        fig.savefig(TEMPFILE)\n",
    "        # print(TEMPFILE)\n",
    "        plt.close()\n",
    "        self.snaps.append(im.fromarray(np.asarray(im.open(TEMPFILE))))\n",
    "\n",
    "    def initialize(self):\n",
    "        return self.data[np.random.choice(range(len(self.data)),self.k, replace = False)]\n",
    "    \n",
    "    def distance(self,x,y):\n",
    "        return  np.linalg.norm(x-y)\n",
    "    \n",
    "                         \n",
    "    def assign(self, centers):\n",
    "        for i in range(len(self.data)):\n",
    "            delta = [float('inf'),0]\n",
    "            for j in range(len(centers)):\n",
    "                distance = self.distance(centers[j],self.data[i])\n",
    "                if distance<delta[0]:\n",
    "                    delta[0] = distance \n",
    "                    delta[1] = j \n",
    "            \n",
    "            self.assignment[i] = delta[1]\n",
    "\n",
    "\n",
    "            \n",
    "    def get_centers(self):\n",
    "        centers = []\n",
    "\n",
    "        for i in set(self.assignment):\n",
    "            cluster = []\n",
    "\n",
    "            for j in range(len(self.data)):\n",
    "                \n",
    "                if self.assignment[j] ==i:\n",
    "                    cluster.append(self.data[j])\n",
    "            x = 0\n",
    "            y = 0\n",
    "            for delta in range(len(cluster)):\n",
    "                x+=cluster[delta][0]\n",
    "                y+=cluster[delta][1]\n",
    "            centers.append([x/len(cluster), y/len(cluster)])\n",
    "        \n",
    "        return np.array(centers)\n",
    "\n",
    "            \n",
    "    def is_diff_centers(self,centers, new_centers):\n",
    "        n = len(centers)\n",
    "        flag = 0\n",
    "        for i in range(n):\n",
    "            if centers[i][0]!=new_centers[i][0]:\n",
    "                flag = 1\n",
    "        \n",
    "        if flag ==1:\n",
    "            return True \n",
    "        return False\n",
    "\n",
    "\n",
    "\n",
    "    def lloyds(self):\n",
    "        # ...\n",
    "        # print(15)\n",
    "        centers = self.initialize()\n",
    "        self.assign(centers)\n",
    "        self.snap(centers)\n",
    "        new_centers = self.get_centers()\n",
    "\n",
    "        while self.is_diff_centers(centers,new_centers):\n",
    "            # print(10)\n",
    "            \n",
    "            self.assign(new_centers)\n",
    "            centers = new_centers\n",
    "            self.snap(centers)\n",
    "            new_centers = self.get_centers()\n",
    "\n",
    "        \n",
    "        return \n",
    "\n",
    "            \n",
    "\n",
    "kmeans = KMeans(X, 4)\n",
    "kmeans.lloyds()\n",
    "images = kmeans.snaps\n",
    "# print(kmeans.snaps)\n",
    "\n",
    "images[0].save(\n",
    "    'kmeans.gif',\n",
    "    optimize=False,\n",
    "    save_all=True,\n",
    "    append_images=images[1:],\n",
    "    loop=0,\n",
    "    duration=500\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "76ca05dc3ea24b2e3b98cdb7774adfbb40773424bf5109b477fd793f623715af"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
